{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fb5caa3",
   "metadata": {},
   "source": [
    "## 3단계: 모델 만들기\n",
    "2_feature_engineering.ipynb 주피터 노트북에서 만들었던 라벨된 피처 데이터를 S3에서 불러와 훈련 데이터와 테스트 데이터로 나눌 것입니다. 그리고 부품의 결함을 예측하기 위한 모델을 만들 것입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "905f48d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 셋팅하기\n",
    "import os\n",
    "import boto3\n",
    "\n",
    "# 파이프라인과 모델 생성을 위한 라이브러리\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, VectorIndexer\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# 데이터 처리를 위한 라이브러리\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dd0fb5",
   "metadata": {},
   "source": [
    "### 피처 데이터 세트 가져오기\n",
    "2_feature_engineering.ipynb 주피터 노트북에서 생성했던 피처 데이터를 가져옵니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c33d7e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>machineID</th>\n",
       "      <th>dt_truncated</th>\n",
       "      <th>volt_rollingmean_12</th>\n",
       "      <th>rotate_rollingmean_12</th>\n",
       "      <th>pressure_rollingmean_12</th>\n",
       "      <th>vibration_rollingmean_12</th>\n",
       "      <th>volt_rollingmean_24</th>\n",
       "      <th>rotate_rollingmean_24</th>\n",
       "      <th>pressure_rollingmean_24</th>\n",
       "      <th>vibration_rollingmean_24</th>\n",
       "      <th>...</th>\n",
       "      <th>volt_rollingstd_24</th>\n",
       "      <th>rotate_rollingstd_24</th>\n",
       "      <th>pressure_rollingstd_24</th>\n",
       "      <th>vibration_rollingstd_24</th>\n",
       "      <th>volt_rollingstd_36</th>\n",
       "      <th>rotate_rollingstd_36</th>\n",
       "      <th>pressure_rollingstd_36</th>\n",
       "      <th>vibration_rollingstd_36</th>\n",
       "      <th>failure</th>\n",
       "      <th>label_e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>2016-01-01 12:00:00</td>\n",
       "      <td>165.702173</td>\n",
       "      <td>455.766882</td>\n",
       "      <td>101.902947</td>\n",
       "      <td>39.639879</td>\n",
       "      <td>165.637453</td>\n",
       "      <td>452.475071</td>\n",
       "      <td>99.827770</td>\n",
       "      <td>39.824437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>166.603907</td>\n",
       "      <td>447.205223</td>\n",
       "      <td>99.023361</td>\n",
       "      <td>39.672101</td>\n",
       "      <td>167.830647</td>\n",
       "      <td>445.184014</td>\n",
       "      <td>99.127203</td>\n",
       "      <td>39.866664</td>\n",
       "      <td>...</td>\n",
       "      <td>1.189061</td>\n",
       "      <td>2.454594</td>\n",
       "      <td>0.554850</td>\n",
       "      <td>0.447165</td>\n",
       "      <td>1.043790</td>\n",
       "      <td>0.560140</td>\n",
       "      <td>0.332557</td>\n",
       "      <td>0.199284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>2015-12-31 12:00:00</td>\n",
       "      <td>169.057387</td>\n",
       "      <td>443.162804</td>\n",
       "      <td>99.231046</td>\n",
       "      <td>40.061227</td>\n",
       "      <td>169.796918</td>\n",
       "      <td>435.977714</td>\n",
       "      <td>100.219854</td>\n",
       "      <td>38.872411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.449784</td>\n",
       "      <td>2.017003</td>\n",
       "      <td>0.583172</td>\n",
       "      <td>0.253893</td>\n",
       "      <td>0.442978</td>\n",
       "      <td>1.071922</td>\n",
       "      <td>0.332810</td>\n",
       "      <td>0.116037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>2015-12-31 00:00:00</td>\n",
       "      <td>170.536450</td>\n",
       "      <td>428.792623</td>\n",
       "      <td>101.208663</td>\n",
       "      <td>37.683596</td>\n",
       "      <td>170.932927</td>\n",
       "      <td>437.500517</td>\n",
       "      <td>100.646320</td>\n",
       "      <td>38.129784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.823724</td>\n",
       "      <td>2.002825</td>\n",
       "      <td>0.342686</td>\n",
       "      <td>0.253877</td>\n",
       "      <td>0.677239</td>\n",
       "      <td>1.070410</td>\n",
       "      <td>0.793118</td>\n",
       "      <td>0.171761</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>2015-12-30 12:00:00</td>\n",
       "      <td>171.329404</td>\n",
       "      <td>446.208410</td>\n",
       "      <td>100.083978</td>\n",
       "      <td>38.575972</td>\n",
       "      <td>168.801770</td>\n",
       "      <td>442.079976</td>\n",
       "      <td>100.462764</td>\n",
       "      <td>38.314688</td>\n",
       "      <td>...</td>\n",
       "      <td>1.278771</td>\n",
       "      <td>1.976804</td>\n",
       "      <td>1.209214</td>\n",
       "      <td>0.271177</td>\n",
       "      <td>0.550194</td>\n",
       "      <td>0.831818</td>\n",
       "      <td>0.193804</td>\n",
       "      <td>0.129767</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>26</td>\n",
       "      <td>2015-12-30 00:00:00</td>\n",
       "      <td>166.274135</td>\n",
       "      <td>437.951542</td>\n",
       "      <td>100.841550</td>\n",
       "      <td>38.053403</td>\n",
       "      <td>169.554872</td>\n",
       "      <td>440.233805</td>\n",
       "      <td>101.490006</td>\n",
       "      <td>37.385859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.915386</td>\n",
       "      <td>1.611549</td>\n",
       "      <td>0.478531</td>\n",
       "      <td>0.151568</td>\n",
       "      <td>0.613444</td>\n",
       "      <td>1.413596</td>\n",
       "      <td>0.606638</td>\n",
       "      <td>0.094085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26</td>\n",
       "      <td>2015-12-29 12:00:00</td>\n",
       "      <td>172.835608</td>\n",
       "      <td>442.516069</td>\n",
       "      <td>102.138461</td>\n",
       "      <td>36.718315</td>\n",
       "      <td>172.801718</td>\n",
       "      <td>442.802266</td>\n",
       "      <td>100.235111</td>\n",
       "      <td>37.056091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.724528</td>\n",
       "      <td>2.909094</td>\n",
       "      <td>0.558389</td>\n",
       "      <td>0.163627</td>\n",
       "      <td>0.603856</td>\n",
       "      <td>2.646676</td>\n",
       "      <td>0.660504</td>\n",
       "      <td>0.087860</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>26</td>\n",
       "      <td>2015-12-29 00:00:00</td>\n",
       "      <td>172.767828</td>\n",
       "      <td>443.088463</td>\n",
       "      <td>98.331761</td>\n",
       "      <td>37.393867</td>\n",
       "      <td>174.436946</td>\n",
       "      <td>441.149097</td>\n",
       "      <td>99.964685</td>\n",
       "      <td>38.452211</td>\n",
       "      <td>...</td>\n",
       "      <td>1.127955</td>\n",
       "      <td>4.161043</td>\n",
       "      <td>0.214182</td>\n",
       "      <td>0.304616</td>\n",
       "      <td>0.448994</td>\n",
       "      <td>0.865341</td>\n",
       "      <td>0.536995</td>\n",
       "      <td>0.176725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>26</td>\n",
       "      <td>2015-12-28 12:00:00</td>\n",
       "      <td>176.106064</td>\n",
       "      <td>439.209732</td>\n",
       "      <td>101.597610</td>\n",
       "      <td>39.510554</td>\n",
       "      <td>172.794005</td>\n",
       "      <td>456.519796</td>\n",
       "      <td>98.924274</td>\n",
       "      <td>39.245226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.473582</td>\n",
       "      <td>3.814364</td>\n",
       "      <td>0.292487</td>\n",
       "      <td>0.375115</td>\n",
       "      <td>0.381619</td>\n",
       "      <td>3.117538</td>\n",
       "      <td>0.543130</td>\n",
       "      <td>0.094798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>26</td>\n",
       "      <td>2015-12-28 00:00:00</td>\n",
       "      <td>169.481945</td>\n",
       "      <td>473.829861</td>\n",
       "      <td>96.250937</td>\n",
       "      <td>38.979898</td>\n",
       "      <td>172.361398</td>\n",
       "      <td>464.973274</td>\n",
       "      <td>95.965903</td>\n",
       "      <td>38.913203</td>\n",
       "      <td>...</td>\n",
       "      <td>1.107598</td>\n",
       "      <td>3.267389</td>\n",
       "      <td>0.257612</td>\n",
       "      <td>0.206946</td>\n",
       "      <td>0.778525</td>\n",
       "      <td>1.566241</td>\n",
       "      <td>0.318768</td>\n",
       "      <td>0.240451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   machineID         dt_truncated  volt_rollingmean_12  rotate_rollingmean_12  \\\n",
       "0         26  2016-01-01 12:00:00           165.702173             455.766882   \n",
       "1         26  2016-01-01 00:00:00           166.603907             447.205223   \n",
       "2         26  2015-12-31 12:00:00           169.057387             443.162804   \n",
       "3         26  2015-12-31 00:00:00           170.536450             428.792623   \n",
       "4         26  2015-12-30 12:00:00           171.329404             446.208410   \n",
       "5         26  2015-12-30 00:00:00           166.274135             437.951542   \n",
       "6         26  2015-12-29 12:00:00           172.835608             442.516069   \n",
       "7         26  2015-12-29 00:00:00           172.767828             443.088463   \n",
       "8         26  2015-12-28 12:00:00           176.106064             439.209732   \n",
       "9         26  2015-12-28 00:00:00           169.481945             473.829861   \n",
       "\n",
       "   pressure_rollingmean_12  vibration_rollingmean_12  volt_rollingmean_24  \\\n",
       "0               101.902947                 39.639879           165.637453   \n",
       "1                99.023361                 39.672101           167.830647   \n",
       "2                99.231046                 40.061227           169.796918   \n",
       "3               101.208663                 37.683596           170.932927   \n",
       "4               100.083978                 38.575972           168.801770   \n",
       "5               100.841550                 38.053403           169.554872   \n",
       "6               102.138461                 36.718315           172.801718   \n",
       "7                98.331761                 37.393867           174.436946   \n",
       "8               101.597610                 39.510554           172.794005   \n",
       "9                96.250937                 38.979898           172.361398   \n",
       "\n",
       "   rotate_rollingmean_24  pressure_rollingmean_24  vibration_rollingmean_24  \\\n",
       "0             452.475071                99.827770                 39.824437   \n",
       "1             445.184014                99.127203                 39.866664   \n",
       "2             435.977714               100.219854                 38.872411   \n",
       "3             437.500517               100.646320                 38.129784   \n",
       "4             442.079976               100.462764                 38.314688   \n",
       "5             440.233805               101.490006                 37.385859   \n",
       "6             442.802266               100.235111                 37.056091   \n",
       "7             441.149097                99.964685                 38.452211   \n",
       "8             456.519796                98.924274                 39.245226   \n",
       "9             464.973274                95.965903                 38.913203   \n",
       "\n",
       "   ...  volt_rollingstd_24  rotate_rollingstd_24  pressure_rollingstd_24  \\\n",
       "0  ...            0.000000              0.000000                0.000000   \n",
       "1  ...            1.189061              2.454594                0.554850   \n",
       "2  ...            0.449784              2.017003                0.583172   \n",
       "3  ...            0.823724              2.002825                0.342686   \n",
       "4  ...            1.278771              1.976804                1.209214   \n",
       "5  ...            0.915386              1.611549                0.478531   \n",
       "6  ...            0.724528              2.909094                0.558389   \n",
       "7  ...            1.127955              4.161043                0.214182   \n",
       "8  ...            0.473582              3.814364                0.292487   \n",
       "9  ...            1.107598              3.267389                0.257612   \n",
       "\n",
       "   vibration_rollingstd_24  volt_rollingstd_36  rotate_rollingstd_36  \\\n",
       "0                 0.000000            0.000000              0.000000   \n",
       "1                 0.447165            1.043790              0.560140   \n",
       "2                 0.253893            0.442978              1.071922   \n",
       "3                 0.253877            0.677239              1.070410   \n",
       "4                 0.271177            0.550194              0.831818   \n",
       "5                 0.151568            0.613444              1.413596   \n",
       "6                 0.163627            0.603856              2.646676   \n",
       "7                 0.304616            0.448994              0.865341   \n",
       "8                 0.375115            0.381619              3.117538   \n",
       "9                 0.206946            0.778525              1.566241   \n",
       "\n",
       "   pressure_rollingstd_36  vibration_rollingstd_36  failure  label_e  \n",
       "0                0.000000                 0.000000      0.0      0.0  \n",
       "1                0.332557                 0.199284      0.0      0.0  \n",
       "2                0.332810                 0.116037      0.0      0.0  \n",
       "3                0.793118                 0.171761      0.0      0.0  \n",
       "4                0.193804                 0.129767      0.0      0.0  \n",
       "5                0.606638                 0.094085      0.0      0.0  \n",
       "6                0.660504                 0.087860      0.0      0.0  \n",
       "7                0.536995                 0.176725      0.0      0.0  \n",
       "8                0.543130                 0.094798      0.0      0.0  \n",
       "9                0.318768                 0.240451      0.0      0.0  \n",
       "\n",
       "[10 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# S3 스토리지 관련 정보\n",
    "bucket = 'jdkimexample'\n",
    "key = 'train/train.csv'\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "labeled_features = s3.get_object(Bucket=bucket,Key=key)\n",
    "data = pd.read_csv(labeled_features['Body'])\n",
    "feat_data = spark.createDataFrame(data)\n",
    "\n",
    "feat_data.limit(10).toPandas().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc840685",
   "metadata": {},
   "source": [
    "### 훈련/테스트 데이터 준비\n",
    "머신러닝의 기본 방법은 모델을 보정하고 테스트하는 데 훈련 때 사용했던 데이터를 사용하지 않는 것입니다. 모델을 평가하기 위해 훈련 데이터와 테스트 데이터로 나눠야하고 일반적으로 데이터의 80%는 모델을 훈련하는데 사용하고, 나머지 10%씩은 매개변수를 보정하고 모델을 평가하는데 사용됩니다.\n",
    "\n",
    "일반적으로 무작위로 분할해서 사용할 수 있지만 시계열 데이터는 관측값 간에 고유한 상관 관계가 있기 때문에 예지 정비 같은 경우에는 시간을 기준으로 분리하는 것이 더 나은 접근 방식인 경우가 많습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e17bc2d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['volt_rollingmean_12',\n",
       " 'rotate_rollingmean_12',\n",
       " 'pressure_rollingmean_12',\n",
       " 'vibration_rollingmean_12',\n",
       " 'volt_rollingmean_24',\n",
       " 'rotate_rollingmean_24',\n",
       " 'pressure_rollingmean_24',\n",
       " 'vibration_rollingmean_24',\n",
       " 'volt_rollingmean_36',\n",
       " 'vibration_rollingmean_36',\n",
       " 'rotate_rollingmean_36',\n",
       " 'pressure_rollingmean_36',\n",
       " 'volt_rollingstd_12',\n",
       " 'rotate_rollingstd_12',\n",
       " 'pressure_rollingstd_12',\n",
       " 'vibration_rollingstd_12',\n",
       " 'volt_rollingstd_24',\n",
       " 'rotate_rollingstd_24',\n",
       " 'pressure_rollingstd_24',\n",
       " 'vibration_rollingstd_24',\n",
       " 'volt_rollingstd_36',\n",
       " 'rotate_rollingstd_36',\n",
       " 'pressure_rollingstd_36',\n",
       " 'vibration_rollingstd_36']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define list of input columns for downstream modeling\n",
    "\n",
    "# We'll use the known label, and key variables.\n",
    "label_var = ['label_e']\n",
    "key_cols =['machineID','dt_truncated']\n",
    "\n",
    "# Then get the remaing feature names from the data\n",
    "input_features = feat_data.columns\n",
    "\n",
    "# We'll use the known label, key variables and \n",
    "# a few extra columns we won't need.\n",
    "remove_names = label_var + key_cols + ['failure','model_encoded','model' ]\n",
    "\n",
    "# Remove the extra names if that are in the input_features list\n",
    "input_features = [x for x in input_features if x not in set(remove_names)]\n",
    "\n",
    "input_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39455e7",
   "metadata": {},
   "source": [
    "스파크 모델은 벡터화된 데이터 프레임이 필요합니다. 여기서 데이터 세트를 변환한 다음 데이터를 훈련 및 테스트 세트로 나눕니다. 이 분할 데이터를 사용하여 9개월 분량의 데이터로 모델을 학습하고 남은 3개월로 모델을 평가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90c88f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60334\n",
      "12808\n"
     ]
    }
   ],
   "source": [
    "# assemble features\n",
    "va = VectorAssembler(inputCols=(input_features), outputCol='features')\n",
    "feat_data = va.transform(feat_data).select('machineID','dt_truncated','label_e','features')\n",
    "\n",
    "# set maxCategories so features with > 10 distinct values are treated as continuous.\n",
    "featureIndexer = VectorIndexer(inputCol=\"features\", \n",
    "                               outputCol=\"indexedFeatures\", \n",
    "                               maxCategories=10).fit(feat_data)\n",
    "\n",
    "# fit on whole dataset to include all labels in index\n",
    "labelIndexer = StringIndexer(inputCol=\"label_e\", outputCol=\"indexedLabel\").fit(feat_data)\n",
    "\n",
    "# split the data into train/test based on date\n",
    "split_date = \"2015-10-30\"\n",
    "training = feat_data.filter(feat_data.dt_truncated < split_date)\n",
    "testing = feat_data.filter(feat_data.dt_truncated >= split_date)\n",
    "\n",
    "print(training.count())\n",
    "print(testing.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a51b23",
   "metadata": {},
   "source": [
    "### 분류 모델\n",
    "예지 정비에서 특히 문제가 되는 부분은 기계의 결함이 일반적으로 정상 작동에서 드물게 발생한다는 점입니다. 그 결과 레이블 분포에 불균형이 생기게 되고 이러한 불균형은 알고리즘이 다수의 데이터를 가진 클래스를 기준으로 분류하려는 경향이 있어 성능 저하를 발생시킬 수 있습니다. 다수의 데이터를 가진 클래스에 올바른 레이블이 지정될 때 전체 오류가 훨씬 개선되기 때문입니다. 그러나 잘못된 예측의 비용이 매우 높을 때 이는 더 큰 문제를 발생시킬 수 있습니다. 이 문제를 해결하기 위해 소수 데이터를 가진 클래스를 오버 샘플링을 할 수 있습니다. 이런 문제 때문에 정확도 이외의 평가 지표를 살펴보는 것도 중요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25079282",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\",\n",
    "                                      # Maximum depth of the tree. (>= 0) \n",
    "                                      # E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'\n",
    "                                      maxDepth=15,\n",
    "                                      # Max number of bins for discretizing continuous features. \n",
    "                                      # Must be >=2 and >= number of categories for any categorical feature.\n",
    "                                      maxBins=32, \n",
    "                                      # Minimum number of instances each child must have after split. \n",
    "                                      # If a split causes the left or right child to have fewer than \n",
    "                                      # minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.\n",
    "                                      minInstancesPerNode=1, \n",
    "                                      # Minimum information gain for a split to be considered at a tree node.\n",
    "                                      minInfoGain=0.0, \n",
    "                                      # Criterion used for information gain calculation (case-insensitive). \n",
    "                                      # Supported options: entropy, gini')\n",
    "                                      impurity=\"gini\")\n",
    "\n",
    "# chain indexers and model in a Pipeline\n",
    "pipeline_cls_mthd = Pipeline(stages=[labelIndexer, featureIndexer, model])\n",
    "\n",
    "# train model.  This also runs the indexers.\n",
    "model_pipeline = pipeline_cls_mthd.fit(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45c3801",
   "metadata": {},
   "source": [
    "이 모델을 평가하기 위해 테스트 데이터 세트에 대한 부품 결함을 예측해봅니다. 테스트 데이터 세트는 모델이 이전에 본 적이 없는 데이터에서 생성이 되었기 때문에 새로운 데이터를 가지고 시뮬레이션을 하는 것과 유사합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d958000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indexedLabel_prediction</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11477</td>\n",
       "      <td>132</td>\n",
       "      <td>98</td>\n",
       "      <td>94</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>243</td>\n",
       "      <td>62</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>164</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>175</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>128</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  indexedLabel_prediction    0.0  1.0  2.0  3.0  4.0\n",
       "0                     0.0  11477  132   98   94   79\n",
       "1                     1.0    243   62   18    3    3\n",
       "2                     2.0    164    3   45    5    2\n",
       "3                     3.0    175    6    3   26    3\n",
       "4                     4.0    128   10    1    2   26"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make predictions. The Pipeline does all the same operations on the test data\n",
    "predictions = model_pipeline.transform(testing)\n",
    "\n",
    "# Create the confusion matrix for the multiclass prediction results\n",
    "# This result assumes a decision boundary of p = 0.5\n",
    "conf_table = predictions.stat.crosstab('indexedLabel', 'prediction')\n",
    "confuse = conf_table.toPandas()\n",
    "confuse.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b13fe0",
   "metadata": {},
   "source": [
    "Confusion matrix는 각각의 실제 부품 결함의 종류는 행에 나열하고 예측된 값은 열에 나타내는 구조입니다. 0.0으로 매겨진 레이블은 부품 결함이 없는 것을 나타내며 1.0에서 4.0까지 번호가 매겨진 레이블은 장비에서 4가지 부품 중 하나에서 결함이 발생했다는 것을 뜻합니다. 예를 들어, 맨 위 행의 세 번째 숫자는 부품에 실제로 결함이 없지만 모델은 부품 2번에서 결함이 발생했을 것이라고 예측한 경우입니다. \n",
    "\n",
    "여기서 올바르게 예측한 것은 대각선을 따라 읽을 수 있는 값입니다. 대각선 위의 숫자는 모델에 결함이 발생하지 않았을 때 결함이 발생했다고 예측한 것이고, 아래쪽은 결함이 났는데 결함이 나지 않았다고 예측한 것입니다. \n",
    "\n",
    "일반적으로 분류 모델을 평가할 때는 결과를 단일한 지표로 평가하는 것이 편리합니다. 그러나, 문제에 따라 이런 평가를 단일한 지표로 수행하는 것은 불가능합니다. 그래서 아래와 같은 4가지 지표를 통해 계산합니다.\n",
    "\n",
    "정확도(Accuracy) : 레이블이 지정된 데이터를 얼마나 자주 예측했는지 보고합니다. 클래스에 불균형이 있을 때는 가장 데이터 수가 큰 클래스로 편향될 수 있습니다.\n",
    "\n",
    "예지 정비 문제에는 클래스 불균형이 존재하기 때문에 아래와 같은 나머지 값도 살펴보는 것이 좋습니다.\n",
    "정밀도(Precision) : 정밀도는 모델이 true positive를 얼마나 잘 분류하는지 측정합니다. \n",
    "재현율(Recall) : 재현율은 모델이 양성 샘플을 얼마나 잘 찾을 수 있는지 측정합니다.\n",
    "F1 : F1은 정밀도와 재현율을 모두 고려합니다. F1 점수는 정밀도와 재현율의 조화 평균입니다. \n",
    "\n",
    "이러한 메트릭은 이진 분류에 가장 적합하지만 다중 클래스 분류에도 유용하게 쓰일 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d15071ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.908495\n",
      "Precision = 0.256039\n",
      "Recall = 0.182969\n",
      "F1 = 0.213423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select (prediction, true label) and compute test error\n",
    "# select (prediction, true label) and compute test error\n",
    "# True positives - diagonal failure terms \n",
    "tp = confuse['1.0'][1]+confuse['2.0'][2]+confuse['3.0'][3]+confuse['4.0'][4]\n",
    "\n",
    "# False positves - All failure terms - True positives\n",
    "fp = np.sum(np.sum(confuse[['1.0', '2.0','3.0','4.0']])) - tp\n",
    "\n",
    "# True negatives \n",
    "tn = confuse['0.0'][0]\n",
    "\n",
    "# False negatives total of non-failure column - TN\n",
    "fn = np.sum(np.sum(confuse[['0.0']])) - tn\n",
    "\n",
    "# Accuracy is diagonal/total \n",
    "acc_n = tn + tp\n",
    "acc_d = np.sum(np.sum(confuse[['0.0','1.0', '2.0','3.0','4.0']]))\n",
    "acc = acc_n/acc_d\n",
    "\n",
    "# Calculate precision and recall.\n",
    "prec = tp/(tp+fp)\n",
    "rec = tp/(tp+fn)\n",
    "\n",
    "# Print the evaluation metrics to the notebook\n",
    "print(\"Accuracy = %g\" % acc)\n",
    "print(\"Precision = %g\" % prec)\n",
    "print(\"Recall = %g\" % rec )\n",
    "print(\"F1 = %g\" % (2.0 * prec * rec/(prec + rec)))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eedac9df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(24, {0: 0.0609, 1: 0.146, 2: 0.0502, 3: 0.0411, 4: 0.0787, 5: 0.0259, 6: 0.0567, 7: 0.0867, 8: 0.0231, 9: 0.019, 10: 0.0423, 11: 0.0169, 12: 0.0251, 13: 0.0338, 14: 0.0312, 15: 0.0378, 16: 0.0254, 17: 0.0322, 18: 0.0265, 19: 0.0264, 20: 0.0289, 21: 0.0276, 22: 0.0296, 23: 0.0279})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = model_pipeline.stages[2].featureImportances\n",
    "\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "957d22b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'model/pdmrfull.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-4a7316e8d9fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0ms3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboto3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m's3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0ms3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model/pdmrfull.zip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbucket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model/pdmrfull.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/boto3/s3/inject.py\u001b[0m in \u001b[0;36mupload_file\u001b[0;34m(self, Filename, Bucket, Key, ExtraArgs, Callback, Config)\u001b[0m\n\u001b[1;32m    129\u001b[0m         return transfer.upload_file(\n\u001b[1;32m    130\u001b[0m             \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbucket\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBucket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mKey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             extra_args=ExtraArgs, callback=Callback)\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/boto3/s3/transfer.py\u001b[0m in \u001b[0;36mupload_file\u001b[0;34m(self, filename, bucket, key, callback, extra_args)\u001b[0m\n\u001b[1;32m    277\u001b[0m             filename, bucket, key, extra_args, subscribers)\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0;31m# If a client error was raised, add the backwards compatibility layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;31m# that raises a S3UploadFailedError. These specific errors were only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/s3transfer/futures.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;31m# however if a KeyboardInterrupt is raised we want want to exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;31m# out of this and propogate the exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coordinator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/s3transfer/futures.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;31m# final result.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/s3transfer/tasks.py\u001b[0m in \u001b[0;36m_main\u001b[0;34m(self, transfer_future, **kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0;31m# Call the submit method to start submitting tasks to execute the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;31m# transfer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_submit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransfer_future\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransfer_future\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;31m# If there was an exception raised during the submission of task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/s3transfer/upload.py\u001b[0m in \u001b[0;36m_submit\u001b[0;34m(self, client, config, osutil, request_executor, transfer_future, bandwidth_limiter)\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;31m# Determine the size if it was not provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtransfer_future\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m             \u001b[0mupload_input_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprovide_transfer_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransfer_future\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;31m# Do a multipart upload if needed, otherwise do a regular put object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/s3transfer/upload.py\u001b[0m in \u001b[0;36mprovide_transfer_size\u001b[0;34m(self, transfer_future)\u001b[0m\n\u001b[1;32m    235\u001b[0m         transfer_future.meta.provide_transfer_size(\n\u001b[1;32m    236\u001b[0m             self._osutil.get_file_size(\n\u001b[0;32m--> 237\u001b[0;31m                 transfer_future.meta.call_args.fileobj))\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrequires_multipart_upload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransfer_future\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/s3transfer/utils.py\u001b[0m in \u001b[0;36mget_file_size\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_file_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mopen_file_chunk_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_byte\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/genericpath.py\u001b[0m in \u001b[0;36mgetsize\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;34m\"\"\"Return the size of a file, reported by os.stat().\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model/pdmrfull.zip'"
     ]
    }
   ],
   "source": [
    "\n",
    "# 로컬에 모델 저장하기\n",
    "model_pipeline.write().overwrite().save('model/pdmrfull.model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80ebb945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3에 모델 저장하기\n",
    "import zipfile\n",
    "new_zips= zipfile.ZipFile('model/pdmrfull.zip', 'w')\n",
    "\n",
    "for folder, subfolders, files in os.walk('model/pdmrfull.model'):\n",
    "    for file in files:\n",
    "        new_zips.write(os.path.join(folder, file), os.path.relpath(os.path.join(folder,file), 'model'), compress_type = zipfile.ZIP_DEFLATED)\n",
    " \n",
    "new_zips.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a64ae9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.client('s3')\n",
    "s3.upload_file('model/pdmrfull.zip', bucket, 'model/pdmrfull.zip')\n",
    "\n",
    "\n",
    "print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ac8f252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 가져오기 \n",
    "from pyspark.ml.pipeline import PipelineModel\n",
    "saved_model = PipelineModel.load('model/pdmrfull.model')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12382172",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'jdkimexample'\n",
    "key = 'model/pdmrfull.zip'\n",
    "s3 = boto3.resource('s3')\n",
    "s3.Bucket(bucket).download_file(key, 'pdmrfull.zip')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "270710ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_unzip = zipfile.ZipFile('pdmrfull.zip','r')\n",
    "output_unzip.extractall(\"\")\n",
    "output_unzip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25cd55c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = PipelineModel.load('pdmrfull.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5691eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(input_df):\n",
    "    import json\n",
    "    response = ''\n",
    "    try:\n",
    "        #Get prediction results for the dataframe\n",
    "        \n",
    "        # We'll use the known label, key variables and \n",
    "        # a few extra columns we won't need.\n",
    "        key_cols =['label_e','machineID','dt_truncated', 'failure','model_encoded','model' ]\n",
    "\n",
    "        # Then get the remaing feature names from the data\n",
    "        input_features = input_df.columns\n",
    "\n",
    "        # Remove the extra stuff if it's in the input_df\n",
    "        input_features = [x for x in input_features if x not in set(key_cols)]\n",
    "        \n",
    "        # Vectorize as in model building\n",
    "        va = VectorAssembler(inputCols=(input_features), outputCol='features')\n",
    "        data = va.transform(input_df).select('machineID','features')\n",
    "        score = pipeline.transform(data)\n",
    "        predictions = score.collect()\n",
    "\n",
    "        #Get each scored result\n",
    "        preds = [str(x['prediction']) for x in predictions]\n",
    "        response = \",\".join(preds)\n",
    "    except Exception as e:\n",
    "        print(\"Error: {0}\",str(e))\n",
    "        return (str(e))\n",
    "    \n",
    "    # Return results\n",
    "    print(json.dumps(response))\n",
    "    return json.dumps(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5c9ee597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>machineID</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>(165.70217320642197, 455.76688230562223, 101.9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   machineID                                           features\n",
       "0         26  (165.70217320642197, 455.76688230562223, 101.9..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_cols =['label_e','dt_truncated', 'failure','model_encoded','model' ]\n",
    "\n",
    "# Then get the remaining feature names from the data\n",
    "input_features = feat_data.columns\n",
    "# Remove the extra stuff if it's in the input_df\n",
    "input_features = [x for x in input_features if x not in set(key_cols)]\n",
    "\n",
    "smple = feat_data.sample(False, .8).limit(1).select(input_features)\n",
    "\n",
    "smple.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00493b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: {0} 'Output column features already exists.'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"'Output column features already exists.'\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(smple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaf8bbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
